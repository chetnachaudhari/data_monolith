{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import *\n",
    "\n",
    "def quiet_logs( sc ):\n",
    "  logger = sc._jvm.org.apache.log4j\n",
    "  logger.LogManager.getLogger(\"org\"). setLevel( logger.Level.ERROR )\n",
    "  logger.LogManager.getLogger(\"akka\").setLevel( logger.Level.ERROR )\n",
    "\n",
    "builder = (SparkSession.builder\n",
    "          .config('spark.sql.extensions', 'io.delta.sql.DeltaSparkSessionExtension')\n",
    "          .config('spark.sql.catalog.spark_catalog', 'org.apache.spark.sql.delta.catalog.DeltaCatalog')\n",
    "          .appName('MyApp')\n",
    "          .master('local[*]'))\n",
    "spark = builder.getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\",1)\n",
    "\n",
    "quiet_logs((spark.sparkContext))\n",
    "\n",
    "KAFKA_BOOTSTRAP_SERVERS = \"broker:29092\"\n",
    "KAFKA_TOPIC = \"user-tracker\"\n",
    "\n",
    "from pyspark.sql.functions import col, concat, lit\n",
    "\n",
    "kafka_df = spark.read.format(\"kafka\").option('kafka.bootstrap.servers', KAFKA_BOOTSTRAP_SERVERS)\\\n",
    "      .option('subscribe', KAFKA_TOPIC)\\\n",
    "      .option('startingOffsets', 'earliest')\\\n",
    "      .load()\n",
    "    \n",
    "kafka_df.select(col(\"offset\"), col(\"value\").cast(\"string\")).show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
